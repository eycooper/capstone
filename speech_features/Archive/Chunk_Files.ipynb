{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1a6216-5f93-4188-a374-e7aabe66ab37",
   "metadata": {},
   "source": [
    "# Chunk Files\n",
    "\n",
    "Since our data sample is relatively small we want to try chunking the data so instead of 1 row (set of features) for each eacher we actually have 5 (1 row for each minute of the experiment). However, since we're using the transcripts to get the speaker labels to extract just the teacher's audio I need chunks of the transcripts to align with the video chunks. The transcript timestamps are only labeled when there is a change in speaker so I will use the closest timestamp to determine the start/end time to use for each chunk so it will not be perfect 1 minute segments. We will also need to normalize some features by duration (like words per minute instead of count).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ef2ce7-356d-4649-8ee5-c120c0931329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import wave\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b1c564-c03f-425a-9d25-8fa963fc6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_seconds(timestamp):\n",
    "    # Parse the timestamp as a datetime object\n",
    "    time_obj = datetime.strptime(timestamp, '%M:%S')\n",
    "    \n",
    "    # Convert the datetime object to a timedelta object\n",
    "    time_delta = timedelta(minutes=time_obj.minute, seconds=time_obj.second)\n",
    "    \n",
    "    # Convert the timedelta object to seconds\n",
    "    return time_delta.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e65b14bc-dc5d-4c33-92bc-98e54ddaa82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = '../data/wav_files/'\n",
    "transcript_path = '../data/transcript_files/'\n",
    "\n",
    "chunked_wav_path = '../data/chunked_wav_files/'\n",
    "chunked_transcript_path = '../data/chunked_transcript_files/'\n",
    "\n",
    "file_name = '201_1.24.20_S_SC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41a9e5d5-9f12-4174-b024-d4e82bec0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_wav_transcript_file(file_name, wav_path, transcript_path, chunked_wav_path, chunked_transcript_path, num_chunks = 5):\n",
    "    '''\n",
    "    Split the .wav audio files and transcript .txt files into 1 minute chunk\n",
    "    so that we have num_chunks approximately 1 minute long chunks\n",
    "    \n",
    "    \n",
    "    file_name: name of original file (identifies participant id)\n",
    "    wav_path: directory containing .wav file\n",
    "    transcript_path: directory containing transcript .txt files\n",
    "    chunked_wav_path: directory for chunked .wav files\n",
    "    chunked_transcript_path: directory for chunked transcript files\n",
    "    num_chunks: number of 1 minute chunks to create (5 because videos are approximately 5 minutes long)\n",
    "    '''\n",
    "    \n",
    "    with wave.open(wav_path + file_name + '.wav', 'rb') as wave_file:\n",
    "        # Calculate duration of audio file\n",
    "        # Get the number of frames and the frame rate\n",
    "        num_frames = wave_file.getnframes()\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        # Calculate duration of audio file (in seconds)\n",
    "        duration = num_frames / float(frame_rate)\n",
    "\n",
    "        # Read in transcript file\n",
    "        df = pd.read_csv(transcript_path + file_name + '.txt', \n",
    "                         engine = 'python', \n",
    "                         delimiter = \"                                             \",\n",
    "                         header = None)\n",
    "        df.columns = ['Speaker', 'Timestamp', 'Text']\n",
    "        df['Timestamp_Secs'] = df['Timestamp'].apply(convert_time_to_seconds)\n",
    "\n",
    "        # Calculate the row index of the closest timestamp value to each chunk's seconds\n",
    "        row_indices = [abs(df['Timestamp_Secs'] - (i+1)*60).idxmin() for i in range(num_chunks)]\n",
    "        # Add first row to be start\n",
    "        row_indices.insert(0, 0)\n",
    "        # Update last entry to be last row\n",
    "        row_indices[-1] = df.shape[0] - 1\n",
    "\n",
    "        # Chunk transcript and audio file\n",
    "        for i in range(num_chunks):\n",
    "            current_idx = row_indices[i]\n",
    "            next_idx = row_indices[i+1]\n",
    "            # If first chunk, update start time to be 0\n",
    "            start_time = 0 if i == 0 else df.iloc[current_idx]['Timestamp_Secs']\n",
    "            # If last chunk, update end time to be total duration of file\n",
    "            end_time = duration if i == (num_chunks - 1) else df.iloc[next_idx]['Timestamp_Secs']\n",
    "            # Get timestamp pair\n",
    "            timestamp_pair = (start_time, end_time)\n",
    "\n",
    "            # Extract this chunk's portion of the audio file\n",
    "            start_frame = int(start_time * frame_rate)\n",
    "            end_frame = int(end_time * frame_rate)\n",
    "            wave_file.setpos(start_frame)\n",
    "            segment_frames = wave_file.readframes(end_frame - start_frame)\n",
    "            segment = np.frombuffer(segment_frames, dtype=np.int16)\n",
    "\n",
    "            # Create a new .wav file for this chunk of the audio file\n",
    "            with wave.open(chunked_wav_path + file_name + f'_Chunk_{i}' + '.wav', 'wb') as output_wave_file:\n",
    "                output_wave_file.setnchannels(1)\n",
    "                output_wave_file.setsampwidth(2)\n",
    "                output_wave_file.setframerate(frame_rate)\n",
    "                output_wave_file.setnframes(len(segment))\n",
    "                output_wave_file.writeframes(segment.tobytes())\n",
    "\n",
    "            # Extract this chunk's portion of the transcript\n",
    "            if i != num_chunks - 1:\n",
    "                df_temp = df.iloc[current_idx: next_idx]\n",
    "            else:\n",
    "                df_temp = df.iloc[current_idx: ]\n",
    "            # Remove timestamp in seconds columns that I created\n",
    "            df_temp = df_temp.drop('Timestamp_Secs', axis = 1)\n",
    "            # Save\n",
    "            df_temp.to_csv(chunked_transcript_path + file_name + f'_Chunk_{i}' + '.txt', \n",
    "                           sep = \"\\t\",\n",
    "                           index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f73207-314c-417f-bed8-13c02d4a1097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d7bde6c-d866-435e-9499-f1438b59d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_file('334_10.29.21', wav_path, transcript_path, chunked_wav_path, chunked_transcript_path, num_chunks = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596ecb5-dbcd-493f-9dad-9a178b6799d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546407b-41e3-4a63-a8dd-c6dfd709cba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f239e4a-f002-4b0f-8173-1f3479ae4c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
