{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9545e3-0dd9-43f9-a573-03b71b8ffdb8",
   "metadata": {},
   "source": [
    "# Speech Feature Engineering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9980857-2dce-4005-beee-b029dc7d5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install librosa\n",
    "# pip install my-voice-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f2c5c-3383-4228-a23e-ab869cff96b7",
   "metadata": {},
   "source": [
    "Some install/package related issues:\n",
    "- For pydub was getting \"No such file or directory: 'ffprobe'\" error with pydub so instead used `conda install -c conda-forge ffmpeg` (rather than pip) to install.\n",
    "- For my-voice-analysis was getting \"Try again the sound of the audio was not clear\". I ended up copying the code from that package's repo and modified all the `sourcerun` file paths and now it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4accda4f-d722-4d1f-9a7c-72563ba5e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "mysp=__import__(\"my-voice-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38c0bd5-2971-4ce5-befc-c660fa86c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for audio files\n",
    "m4a_path = './data/m4a_files/'\n",
    "wav_path = './data/wav_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc41d531-63a2-4826-8229-3e31c89320c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_m4a_to_wav(file_name, input_dir, output_dir):\n",
    "    '''\n",
    "    Convert an .m4a audio file to a .wav audio file using PyDub.\n",
    "\n",
    "    Inputs:\n",
    "        file_name (str): name of file (without extension)\n",
    "        input_dir (str): directory path for input .m4a file\n",
    "        output_dir (str): directory path for output .wav file\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Load the m4a file\n",
    "    audio = AudioSegment.from_file(input_dir + file_name + '.m4a', format = 'm4a')\n",
    "#     # Export the audio to wav format\n",
    "#     audio.export(output_dir + file_name + '.wav', format = 'wav')\n",
    "    \n",
    "    # Set the desired sample rate and bit depth\n",
    "    desired_sample_rate = 44100\n",
    "    desired_sample_width = 2  # 16-bit depth\n",
    "\n",
    "    # Resample the audio to the desired sample rate\n",
    "    resampled_audio = audio.set_frame_rate(desired_sample_rate)\n",
    "\n",
    "    # Set the bit depth to the desired value\n",
    "    converted_audio = resampled_audio.set_sample_width(desired_sample_width)\n",
    "\n",
    "    # Export the converted audio to a new WAV file\n",
    "    converted_audio.export(output_dir + file_name + '.wav', format=\"wav\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6b6fb5-0e40-424a-bec2-402c3e2ab411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty directories for wav files (if it doesn't exist)\n",
    "if not os.path.exists(wav_path):\n",
    "    os.makedirs(wav_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea2c612-8cd7-429e-9efb-9729edd46142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file names\n",
    "file_list = os.listdir(m4a_path) # List all files in original directory\n",
    "# Updated list of files names\n",
    "# remove extension and skip files that start with '.' (e.g. ipynb checkpoints)\n",
    "file_list = [x.replace('.m4a', '')for x in file_list if x[0] != '.'] # Remove extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239f8953-bcfb-4625-bde8-c2de786cf4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_temp = file_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc34474e-9173-4ee4-9ab8-b55574c3306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all audio files to wav format\n",
    "for file in file_list_temp:\n",
    "    convert_m4a_to_wav(file, m4a_path, wav_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaedce31-4f31-4805-bc40-2d82d26e4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"348th_11.4.21\" # Audio File title\n",
    "wav_file = wav_path + file_name + '.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550dabe-a019-4be1-aff4-bf43e30c0878",
   "metadata": {},
   "source": [
    "## Librosa Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee0ef8aa-7188-42fe-8e21-78d12d55a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch: (array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n",
      "Loudness: [[-48.007576 -39.336563 -32.142986 ... -22.90003  -24.209024 -26.71492 ]]\n",
      "Spectral centroid: [[1854.40866307  945.04239462  713.05587732 ... 1150.47042849\n",
      "  1063.63073103  891.03299265]]\n"
     ]
    }
   ],
   "source": [
    "# Load the WAV file using librosa\n",
    "y, sr = librosa.load(wav_file)\n",
    "\n",
    "# Extract pitch, loudness, and spectral centroid\n",
    "pitch = librosa.pitch.piptrack(y=y, sr=sr)\n",
    "loudness = librosa.amplitude_to_db(librosa.feature.rms(y=y))\n",
    "spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "# Print the features\n",
    "print(\"Pitch:\", pitch)\n",
    "print(\"Loudness:\", loudness)\n",
    "print(\"Spectral centroid:\", spec_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffb00a-42e4-4282-82df-d84140f5a155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4a30f7-ac60-409d-b4f4-a913488499ae",
   "metadata": {},
   "source": [
    "## my-voice-analysis Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3300ab90-9d35-4d4a-a68a-d026698edd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dataset = mysp.mysptotal(file_name, wav_path[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7378b5bc-5a6d-45f2-af1f-81cb91fd08e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_ of_syllables</th>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_pauses</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_of_speech</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articulation_rate</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaking_duration</th>\n",
       "      <td>150.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_duration</th>\n",
       "      <td>309.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_mean</th>\n",
       "      <td>224.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_std</th>\n",
       "      <td>62.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_median</th>\n",
       "      <td>222.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_min</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_max</th>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_quantile25</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_quan75</th>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "number_ of_syllables     736\n",
       "number_of_pauses         203\n",
       "rate_of_speech             2\n",
       "articulation_rate          5\n",
       "speaking_duration      150.8\n",
       "original_duration      309.3\n",
       "balance                  0.5\n",
       "f0_mean               224.76\n",
       "f0_std                 62.28\n",
       "f0_median              222.7\n",
       "f0_min                    70\n",
       "f0_max                   423\n",
       "f0_quantile25            187\n",
       "f0_quan75                264"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dataset.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1361dd15-a487-4a73-9e2a-b0a2589fc5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a female, mood of speech: Reading, p-value/sample size= :0.00', 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gender recognition and mood of speech:\n",
    "gender_mood = mysp.myspgend(file_name, wav_path[:-1])\n",
    "gender_mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efa5cfe-e69d-4113-994c-33ac7f22870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mood(gender_mood_string):\n",
    "    '''\n",
    "    Want to extract the mood of speech from the gender and mood string from my-voice-analysis package\n",
    "    \n",
    "    For example, from the string:\n",
    "    ('a female, mood of speech: Reading, p-value/sample size= :0.00', 5)\n",
    "    I'd want to return \"Reading\"\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Find the index of the first colon and the next comma after it\n",
    "    colon_index = gender_mood_string.find(':')\n",
    "    comma_index = gender_mood_string.find(',', colon_index)\n",
    "\n",
    "    # Extract the text between the colon and comma using slicing\n",
    "    mood = gender_mood_string[colon_index+2:comma_index]\n",
    "    \n",
    "    return mood\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "818b6672-a060-422d-9d35-8702c0e1d93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reading'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mood = extract_mood(gender_mood[0])\n",
    "mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395501cb-9242-4c3c-ad88-99b1d0dd95fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec7f52-5546-4c22-bd43-a4b8ae31a8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
