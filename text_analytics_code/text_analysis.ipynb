{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f95f6cb-c691-4458-8001-4009ff8f7168",
   "metadata": {},
   "source": [
    "# Text Analysis \n",
    "\n",
    "* Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d33eec3-5321-4171-9af9-43f9c504915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EmmaC\\AppData\\Local\\Temp\\ipykernel_7608\\158841178.py:5: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e22d00-0837-4d85-b527-817a5fe0a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import text files\n",
    "# these are grabbed from the \"text analysis files\" folder on UVA Box\n",
    "\n",
    "LIB = pd.read_csv('../../data/Text Analysis Files/LIB.csv')\n",
    "TOKEN = pd.read_csv('../../data/Text Analysis Files/TOKEN.csv')\n",
    "DOC = pd.read_csv('../../data/Text Analysis Files/DOC.csv')\n",
    "TFIDF = pd.read_csv('../../data/Text Analysis Files/TFIDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d98764-4c4d-46ad-87cf-73822d073bc5",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ff63b5-8357-48f7-b01e-5eaae6a572d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abacus</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13896</th>\n",
       "      <td>zest</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13897</th>\n",
       "      <td>zest</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>zest</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13899</th>\n",
       "      <td>zest</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13900</th>\n",
       "      <td>zip</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13901 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word     sentiment\n",
       "0         abacus         trust\n",
       "1        abandon          fear\n",
       "2        abandon      negative\n",
       "3        abandon       sadness\n",
       "4      abandoned         anger\n",
       "...          ...           ...\n",
       "13896       zest  anticipation\n",
       "13897       zest           joy\n",
       "13898       zest      positive\n",
       "13899       zest         trust\n",
       "13900        zip      negative\n",
       "\n",
       "[13901 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get lexicon\n",
    "## using NRC.csv\n",
    "\n",
    "NRC = pd.read_csv('NRC.csv')\n",
    "NRC.columns = [col.replace('nrc_','') for col in NRC.columns]\n",
    "NRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533b34d7-d96c-44ac-8fb6-d2f5b32eb4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abba</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>zany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>zeal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>zealous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>zest</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>zip</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6467 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_str  anger  anticipation  disgust  fear  joy  negative  \\\n",
       "1          abacus      0             0        0     0    0         0   \n",
       "2         abandon      0             0        0     1    0         1   \n",
       "3       abandoned      1             0        0     1    0         1   \n",
       "4     abandonment      1             0        0     1    0         1   \n",
       "5            abba      0             0        0     0    0         0   \n",
       "...           ...    ...           ...      ...   ...  ...       ...   \n",
       "6463         zany      0             0        0     0    0         0   \n",
       "6464         zeal      0             1        0     0    1         0   \n",
       "6465      zealous      0             0        0     0    1         0   \n",
       "6466         zest      0             1        0     0    1         0   \n",
       "6467          zip      0             0        0     0    0         1   \n",
       "\n",
       "      positive  sadness  surprise  trust  \n",
       "1            0        0         0      1  \n",
       "2            0        1         0      0  \n",
       "3            0        1         0      0  \n",
       "4            0        1         1      0  \n",
       "5            1        0         0      0  \n",
       "...        ...      ...       ...    ...  \n",
       "6463         0        0         1      0  \n",
       "6464         1        0         1      1  \n",
       "6465         1        0         0      1  \n",
       "6466         1        0         0      1  \n",
       "6467         0        0         0      0  \n",
       "\n",
       "[6467 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change table so the sentiments are rows with values 0 or 1 \n",
    "NRC = pd.crosstab(NRC['word'], NRC['sentiment']).reset_index().rename_axis(None, axis=1)\n",
    "NRC=NRC.rename(columns = {'word':'term_str'})\n",
    "NRC = NRC.iloc[1:]\n",
    "#NRC = NRC.astype(object)\n",
    "NRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917ec0cb-90ad-4c3e-bde3-dc8a233fa682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon columns\n",
    "emo_cols = \"anger anticipation disgust fear joy sadness surprise trust polarity\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd43591-afd1-4214-a9da-7fbf676e07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRC['polarity'] = NRC.positive - NRC.negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9b02a6-4739-4c82-a801-92f911b8c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TOKEN\n",
    "# NRC.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84a1654-d848-4935-a74e-f93ca8b8dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKEN.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d40a11-d06a-4005-9fcd-79c49f34b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKEN = TOKEN\n",
    "# #TOKEN = TOKEN.astype(object)\n",
    "# TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d50262-028e-4335-ae70-c11da693c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKEN.term_str.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f746f01e-8279-4de3-88f3-4632b3b54905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRC.term_str.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5754d251-4548-45d4-9ef0-04b2ef4750fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker_id</th>\n",
       "      <th>line_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">201</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>('Good', 'JJ')</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Good</td>\n",
       "      <td>good</td>\n",
       "      <td>542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('morning', 'NN')</td>\n",
       "      <td>NN</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('class', 'NN')</td>\n",
       "      <td>NN</td>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>('I', 'PRP')</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "      <td>621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"'m\", 'VBP')</td>\n",
       "      <td>VBP</td>\n",
       "      <td>'m</td>\n",
       "      <td>m</td>\n",
       "      <td>764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">360</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">47</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">7</th>\n",
       "      <th>6</th>\n",
       "      <td>('spent', 'VBD')</td>\n",
       "      <td>VBD</td>\n",
       "      <td>spent</td>\n",
       "      <td>spent</td>\n",
       "      <td>1246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('oh', 'UH')</td>\n",
       "      <td>UH</td>\n",
       "      <td>oh</td>\n",
       "      <td>oh</td>\n",
       "      <td>892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('it', 'PRP')</td>\n",
       "      <td>PRP</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(\"'s\", 'VBZ')</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>'s</td>\n",
       "      <td>s</td>\n",
       "      <td>1132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('over', 'RP')</td>\n",
       "      <td>RP</td>\n",
       "      <td>over</td>\n",
       "      <td>over</td>\n",
       "      <td>927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48644 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pos_tuple  pos token_str  \\\n",
       "speaker_id line_num sent_num token_num                                     \n",
       "201        1        0        0             ('Good', 'JJ')   JJ      Good   \n",
       "                             1          ('morning', 'NN')   NN   morning   \n",
       "                             2            ('class', 'NN')   NN     class   \n",
       "                    1        0               ('I', 'PRP')  PRP         I   \n",
       "                             1              (\"'m\", 'VBP')  VBP        'm   \n",
       "...                                                   ...  ...       ...   \n",
       "360        47       7        6           ('spent', 'VBD')  VBD     spent   \n",
       "                             8               ('oh', 'UH')   UH        oh   \n",
       "                             10             ('it', 'PRP')  PRP        it   \n",
       "                             11             (\"'s\", 'VBZ')  VBZ        's   \n",
       "                             12            ('over', 'RP')   RP      over   \n",
       "\n",
       "                                       term_str  term_id  anger  anticipation  \\\n",
       "speaker_id line_num sent_num token_num                                          \n",
       "201        1        0        0             good      542    0.0           1.0   \n",
       "                             1          morning      828    0.0           0.0   \n",
       "                             2            class      231    0.0           0.0   \n",
       "                    1        0                i      621    0.0           0.0   \n",
       "                             1                m      764    0.0           0.0   \n",
       "...                                         ...      ...    ...           ...   \n",
       "360        47       7        6            spent     1246    0.0           0.0   \n",
       "                             8               oh      892    0.0           0.0   \n",
       "                             10              it      677    0.0           0.0   \n",
       "                             11               s     1132    0.0           0.0   \n",
       "                             12            over      927    0.0           0.0   \n",
       "\n",
       "                                        disgust  fear  joy  negative  \\\n",
       "speaker_id line_num sent_num token_num                                 \n",
       "201        1        0        0              0.0   0.0  1.0       0.0   \n",
       "                             1              0.0   0.0  0.0       NaN   \n",
       "                             2              0.0   0.0  0.0       NaN   \n",
       "                    1        0              0.0   0.0  0.0       NaN   \n",
       "                             1              0.0   0.0  0.0       NaN   \n",
       "...                                         ...   ...  ...       ...   \n",
       "360        47       7        6              0.0   0.0  0.0       1.0   \n",
       "                             8              0.0   0.0  0.0       NaN   \n",
       "                             10             0.0   0.0  0.0       NaN   \n",
       "                             11             0.0   0.0  0.0       NaN   \n",
       "                             12             0.0   0.0  0.0       NaN   \n",
       "\n",
       "                                        positive  sadness  surprise  trust  \\\n",
       "speaker_id line_num sent_num token_num                                       \n",
       "201        1        0        0               1.0      0.0       1.0    1.0   \n",
       "                             1               NaN      0.0       0.0    0.0   \n",
       "                             2               NaN      0.0       0.0    0.0   \n",
       "                    1        0               NaN      0.0       0.0    0.0   \n",
       "                             1               NaN      0.0       0.0    0.0   \n",
       "...                                          ...      ...       ...    ...   \n",
       "360        47       7        6               0.0      0.0       0.0    0.0   \n",
       "                             8               NaN      0.0       0.0    0.0   \n",
       "                             10              NaN      0.0       0.0    0.0   \n",
       "                             11              NaN      0.0       0.0    0.0   \n",
       "                             12              NaN      0.0       0.0    0.0   \n",
       "\n",
       "                                        polarity  \n",
       "speaker_id line_num sent_num token_num            \n",
       "201        1        0        0               1.0  \n",
       "                             1               0.0  \n",
       "                             2               0.0  \n",
       "                    1        0               0.0  \n",
       "                             1               0.0  \n",
       "...                                          ...  \n",
       "360        47       7        6              -1.0  \n",
       "                             8               0.0  \n",
       "                             10              0.0  \n",
       "                             11              0.0  \n",
       "                             12              0.0  \n",
       "\n",
       "[48644 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_nrc = TOKEN.merge(NRC, on='term_str', how='left').set_index(['speaker_id','line_num','sent_num','token_num'])\n",
    "TOKEN_nrc[emo_cols] = TOKEN_nrc[emo_cols].fillna(0)\n",
    "TOKEN_nrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6563e55-4b30-49fe-9775-8a54f0e833e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save table\n",
    "#TOKEN_nrc.to_csv(\"words_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b144b8-daa0-4cd5-b86c-24aa4452bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest level - all videos together\n",
    "TOKEN_nrc[emo_cols].mean().sort_values().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd7adf-ce10-4840-9063-cafe28d536a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate by speaker \n",
    "# example - speaker id 201\n",
    "speaker_201 = TOKEN_nrc.loc[[201]].copy()\n",
    "speaker_201[emo_cols].mean().sort_values().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d8a088-0e3e-4f2f-91d0-d46e2689aa01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TOKEN_nrc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# separate by speaker\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# full loop\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m speaker \u001b[38;5;129;01min\u001b[39;00m \u001b[43mTOKEN_nrc\u001b[49m\u001b[38;5;241m.\u001b[39mspeaker_id:\n\u001b[0;32m      4\u001b[0m      exec(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m = TOKEN_nrc.loc[[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]].copy()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(speaker))\n\u001b[0;32m      5\u001b[0m      exec(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeaker_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m[emo_cols].mean().sort_values().plot.barh()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(speaker))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TOKEN_nrc' is not defined"
     ]
    }
   ],
   "source": [
    "# separate by speaker\n",
    "# full loop\n",
    "# save plot.barh() to bar_charts folder\n",
    "for speaker in TOKEN_nrc.speaker_id:\n",
    "     exec('speaker_{} = TOKEN_nrc.loc[[{}]].copy()'.format(speaker))\n",
    "     exec('speaker_{}[emo_cols].mean().sort_values().plot.barh().savefig(bar_charts/\\'speaker_{}.png\\''.format(speaker))\n",
    "\n",
    "speaker_360\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6e1dc-b233-4fe3-b99e-d7b49a6f17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line chart visual\n",
    "def plot_sentiments(df, emo='polarity'):\n",
    "    FIG = dict(figsize=(25, 5), legend=True, fontsize=14, rot=45)\n",
    "    df[emo].plot(**FIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68496f2-36a2-4bdc-bc5c-15a1771250d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate by speaker\n",
    "# example - speaker id 201\n",
    "\n",
    "#### looks weird since its not a seamless timeline - would be better at the video level \n",
    "plot_sentiments(speaker_201, ['trust','fear','joy','polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7cc84-2818-4ffb-9be7-5a509fab3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiments(speaker_201, ['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff61189-9192-4b19-9fd3-2a85e8e257aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the sentiment in texts\n",
    "# separating by speaker\n",
    "# example - speaker 201\n",
    "speaker_201['html'] =  speaker_201.apply(lambda x: \"<span class='sent{}'>{}</span>\".format(int(np.sign(x['polarity'])), x.token_str), 1)\n",
    "speaker_201['html'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e8dc5-e3b6-4047-b3d4-a08d2fa6b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group at the sentence level\n",
    "speaker_201_sents = speaker_201.groupby(['speaker_id','line_num','sent_num'])[emo_cols].mean()\n",
    "speaker_201_sents['sent_str'] = speaker_201.groupby(['speaker_id','line_num','sent_num']).term_str.apply(lambda x: x.str.cat(sep=' '))\n",
    "speaker_201_sents['html_str'] = speaker_201.groupby(['speaker_id','line_num','sent_num']).html.apply(lambda x: x.str.cat(sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482b9e2-e202-4f46-827f-cf171c73553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sentences(df, sentiment):\n",
    "    rows = []\n",
    "    for idx in df.sample(10).index:\n",
    "\n",
    "        valence = round(df.loc[idx, sentiment], 4)     \n",
    "        t = 0\n",
    "        if valence > t: color = '#ccffcc'\n",
    "        elif valence < t: color = '#ffcccc'\n",
    "        else: color = '#f2f2f2'\n",
    "        z=0\n",
    "        rows.append(\"\"\"<tr style=\"background-color:{0};padding:.5rem 1rem;font-size:110%;\">\n",
    "        <td>{1}</td><td>{3}</td><td width=\"400\" style=\"text-align:left;\">{2}</td>\n",
    "        </tr>\"\"\".format(color, valence, df.loc[idx, 'html_str'], idx))\n",
    "\n",
    "    display(HTML('<style>#sample1 td{font-size:120%;vertical-align:top;} .sent-1{color:red;font-weight:bold;} .sent1{color:green;font-weight:bold;}</style>'))\n",
    "    display(HTML('<table id=\"sample1\"><tr><th>Sentiment</th><th>ID</th><th width=\"600\">Sentence</th></tr>'+''.join(rows)+'</table>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2657c07-dd0b-4a86-ad7a-77a81772d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences(speaker_201_sents, 'polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166658d7-5dc9-4016-9e71-3dcfcb13e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences(speaker_201_sents, 'trust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28406c-1699-423d-9b31-c48130452e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences(speaker_201_sents, 'fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b99f14-34db-4a0a-ad17-0f9ae7bf08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using vader\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7f144-ef12-4dbb-a254-b7abcba10afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d54f5d-1483-4767-b823-821f238bb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_201_vader_cols = speaker_201_sents.sent_str.apply(analyser.polarity_scores).apply(lambda x: pd.Series(x))\n",
    "speaker_201_vader = pd.concat([speaker_201_sents, speaker_201_vader_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d89e4-7a92-42fa-80cc-fc8bacf9e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = int(speaker_201_vader.shape[0] / 5)\n",
    "speaker_201_vader[['pos','neg']].rolling(w).mean().plot(figsize=(25,5))\n",
    "speaker_201_vader[['neu']].rolling(w).mean().plot(figsize=(25,5))\n",
    "speaker_201_vader[['compound']].rolling(w).mean().plot(figsize=(25,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736f000-32ff-4c8e-b7ee-047433df396c",
   "metadata": {},
   "source": [
    "#### Vader Interpretation\n",
    "* The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation)\n",
    "* The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a ‘normalized, weighted composite score’ is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e280d-146c-4f05-a041-96a22eb7df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate by speaker - get all data/visuals\n",
    "\n",
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
